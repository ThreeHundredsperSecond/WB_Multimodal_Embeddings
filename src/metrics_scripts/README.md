# **Набор скриптов для формирования выборок и подсчета метрик** 


##  `compute_metrics_logreg.py` — 
это скрипт для вычисления метрик бинарной классификации с использованием логистической регрессии. Скрипт поддерживает обработку текстовых и изображенных данных, а также их комбинаций и преобразованных через PCA версий. Он предназначен для анализа эффективности различных моделей и подходов в задачах бинарной классификации.


### Аргументы командной строки

Скрипт поддерживает следующие аргументы командной строки:

- `--emb_path` (обязательный): Пути к файлам с эмбеддингами (`.npz`), разделенные пробелом.
- `--tasks` (обязательный): Список имен задач, разделенных пробелом.
- `--df_paths` (обязательный): Список путей к CSV-файлам с данными для каждой задачи, разделенных пробелом. Для каждой задачи пути к файлам должны быть разделены запятыми.
- `--save_path` (обязательный): Путь для сохранения результирующего CSV файла с метриками.
- `--model_names` (обязательный): Список имен моделей, соответствующих файлам эмбеддингов, разделенных пробелом.

### Пример использования

```bash
python compute_metrics_logreg.py --emb_path "path/to/embeddings1.npz path/to/embeddings2.npz" --tasks "task1 task2" --df_paths "path/to/task1_data.csv,path/to/task2_data.csv" --save_path "path/to/results.csv" --model_names "model1 model2"
```

В этом примере скрипт будет обрабатывать эмбеддинги из двух файлов `.npz`, соответствующих двум разным моделям (`model1` и `model2`) и двум задачам (`task1` и `task2`). Для каждой задачи указаны пути к двум CSV-файлам с данными (`path/to/task1_data.csv` для `task1` и `path/to/task2_data.csv` для `task2`). Результаты будут сохранены в файл `path/to/results.csv`.

### Описание работы скрипта

1. **Загрузка данных:** Скрипт загружает эмбеддинги для текста и изображений из указанных `.npz` файлов, а также данные целевой переменной из CSV-файлов.
2. **Обработка данных:** Для каждой задачи данные обрабатываются отдельно, включая возможность применения PCA для сокращения размерности данных.
3. **Вычисление метрик:** С использованием логистической регрессии скрипт вычисляет метрики бинарной классификации (F1-мера, точность, полнота) для каждой комбинации данных (текст, изображение, объединенные, PCA-преобразованные).
4. **Сохранение результатов:** Результаты вычислений сохраняются в указанный CSV-файл.




## `compute_metrics_mlp_binary.py` — 
это скрипт для вычисления метрик (F1, точность, полнота) бинарной классификации с использованием многослойного перцептрона (MLP) 
или на основе предварительно вычисленных эмбеддингов текста и изображений. Скрипт поддерживает работу с различными типами данных,
включая текст, изображения, их комбинации и PCA-преобразованные данные.




### Параметры командной строки

Скрипт поддерживает следующие аргументы командной строки для настройки процесса вычисления метрик:

- `--model_names`: Список имен моделей (например, для различения результатов в выходном файле).
- `--emb_path`: Пути к файлам с эмбеддингами (`.npz`), содержащими эмбеддинги текста (`text`) и изображений (`img`).
- `--tasks`: Список имен задач (используется для метаинформации в выходном файле).
- `--df_paths`: Пути к CSV-файлам с данными, где каждый файл должен содержать колонку `target` с метками классов.
- `--save_path`: Путь к файлу, в который будут сохранены результаты вычислений.
- `--average`: Метод усреднения для вычисления метрик (поддерживаются `binary`, `micro`, `macro`, `weighted`).

### Пример использования

```bash
python compute_metrics_mlp_binary.py --model_names "model1" --emb_path "D:\\ruclip-vit-base-patch32-384_embeddings.npz" --tasks "task1" --df_paths "D:\male_famele.csv" --save_path "D:\scripts\test\results.csv"
```   

В этом примере скрипт вычислит метрики для двух задач (`Task1` и `Task2`), используя данные из соответствующих файлов эмбеддингов и меток классов. Результаты будут сохранены в `path/to/results.csv`.

### Описание работы скрипта

1. **Загрузка данных:** Для каждой задачи скрипт загружает соответствующие эмбеддинги текста и изображений из указанных файлов `.npz`, а также метки классов из CSV-файлов.
2. **Обработка данных:** Выполняется нормализация данных, их конкатенация и, при необходимости, применение PCA.
3. **Классификация:** Для каждого типа данных (текст, изображение, комбинация, PCA) выполняется обучение и валидация модели MLPClassifier, вычисляются метрики.
4. **Сохранение результатов:** Результаты вычислений (средние значения F1, точности и полноты) для каждого типа данных сохраняются в указанный файл.






## `compute_metrics_mlp_multiclass.py` — это скрипт для вычисления метрик (F1, точность, полнота) 
мультиклассовой классификации с использованием многослойного перцептрона (MLP). 
Скрипт обрабатывает эмбеддинги текста и изображений, поддерживая работу с текстовыми данными, изображениями,
их комбинациями и PCA-преобразованными данными.



### Параметры командной строки

Скрипт поддерживает следующие аргументы командной строки для настройки процесса вычисления метрик:

- `--model_names`: Список имен моделей (например, для различения результатов в выходном файле).
- `--emb_path`: Пути к файлам с эмбеддингами (`.npz`), содержащими эмбеддинги текста (`text`) и изображений (`img`).
- `--tasks`: Список имен задач (используется для метаинформации в выходном файле).
- `--dfs`: Пути к CSV-файлам с данными, где каждый файл должен содержать колонку `target` с метками классов.
- `--save_path`: Путь к файлу, в который будут сохранены результаты вычислений.
- `--average`: Метод усреднения для вычисления метрик (поддерживаются `micro`, `macro`, `weighted`).

### Пример использования

```bash
python compute_metrics_mlp_multiclass.py --model_names model1 model2 --emb_path path/to/embeddings1.npz path/to/embeddings2.npz --tasks Task1 Task2 --dfs path/to/task1_labels.csv path/to/task2_labels.csv --save_path path/to/results.csv --average weighted
```

В этом примере скрипт вычислит метрики для двух задач (`Task1` и `Task2`), используя данные из соответствующих файлов эмбеддингов и меток классов. Результаты будут сохранены в `path/to/results.csv`.

### Описание работы скрипта

1. **Загрузка данных:** Для каждой задачи скрипт загружает соответствующие эмбеддинги текста и изображений из указанных файлов `.npz`, а также метки классов из CSV-файлов.
2. **Обработка данных:** Выполняется стандартизация данных, их конкатенация и, при необходимости, применение PCA для снижения размерности.
3. **Классификация:** Для каждого типа данных (текст, изображение, комбинация, PCA) выполняется обучение и валидация модели MLPClassifier, вычисляются метрики.
4. **Сохранение результатов:** Результаты вычислений (средние значения F1, точности и полноты) для каждого типа данных сохраняются в указанный файл.







## `compute_metrics_multiclass_logreg.py` — 

это скрипт для вычисления метрик мультиклассовой классификации с использованием логистической регрессии. Он предназначен для работы с эмбеддингами текста и изображений, их комбинациями и преобразованными через PCA данными. Скрипт позволяет оценить эффективность различных подходов классификации на множестве категорий.


Убедитесь, что все зависимости установлены в вашем окружении перед запуском скрипта.

### Параметры командной строки

- `--model_names` (обязательно): Список имен моделей.
- `--emb_path` (обязательно): Пути к файлам с эмбеддингами (`.npz`), разделенные пробелами.
- `--tasks` (обязательно): Список имен задач.
- `--dfs` (обязательно): Пути к CSV-файлам с данными для каждой задачи. Каждый файл должен содержать колонку `category` с категориями.
- `--save_path` (обязательно): Путь для сохранения результирующего файла с метриками (CSV).

### Пример использования

```bash
python compute_metrics_multiclass_logreg.py --model_names model1 model2 --emb_path path/to/embeddings1.npz path/to/embeddings2.npz --tasks Task1 Task2 --dfs path/to/task1_labels.csv path/to/task2_labels.csv --save_path path/to/results.csv
```

Этот пример произведет вычисление метрик для двух моделей (`model1` и `model2`) на основе данных, содержащихся в файлах эмбеддингов и меток для двух задач (`Task1` и `Task2`). Результаты будут сохранены в файл `path/to/results.csv`.

### Описание работы скрипта

1. **Загрузка и подготовка данных:** Для каждой задачи скрипт загружает соответствующие эмбеддинги и метки классов. Метки классов кодируются в числовой формат.
2. **Вычисление метрик:** Скрипт обрабатывает текстовые и изображенные данные, их комбинации, а также данные, преобразованные через PCA, для каждой задачи. Для каждого типа данных вычисляются метрики мультиклассовой классификации (F1-мера, точность, полнота) с использованием логистической регрессии.
3. **Сохранение результатов:** Результаты вычислений сохраняются в указанный файл CSV.

## `prepare_adult_child_dataset.py`  скрипт выполняет следующие задачи:

1. Определяет класс `TextNormalizer` для нормализации и очистки текста. Он использует библиотеки Natasha для русского языка и spaCy для английского языка. Методы класса включают:
   - `clean_text`: удаляет HTML-теги, знаки пунктуации и определенные ключевые слова из текста.
   - `normalize_text`: лемматизирует текст на основе языка (русский или английский).
   - `detect_language`: определяет язык текста (русский или английский) на основе наличия кириллических символов.
   - `normalize_df`: применяет очистку и нормализацию текста к указанным столбцам DataFrame.

2. Определяет функцию `prepare_adult_child_dataset`, которая подготавливает набор данных для классификации одежды на взрослую и детскую. Она выполняет следующие шаги:
   - Фильтрует DataFrame `test_df` на основе категорий одежды.
   - Нормализует текстовые описания одежды с помощью класса `TextNormalizer`.
   - Определяет ключевые слова для взрослой и детской одежды.
   - Фильтрует одежду на основе наличия ключевых слов в описаниях.
   - Создает отдельные DataFrame для взрослой и детской одежды.
   - Добавляет дополнительные категории одежды для детей.
   - Объединяет взрослую и детскую одежду в один DataFrame.
   - Создает целевые метки (0 для взрослой одежды, 1 для детской одежды).
   - Возвращает DataFrame с индексами и целевыми метками.

Входные данные:
- `test_df`: DataFrame с данными об одежде, включая столбцы 'category' и 'description'.

Выходные данные:
- `is_child_df`: DataFrame с двумя столбцами: 'index' (индексы элементов одежды) и 'target' (целевые метки: 0 для взрослой одежды, 1 для детской одежды).

Скрипт использует библиотеки pandas, numpy, re, spacy, unicodedata и natasha.

Пример использования:
```python
test_df = pd.read_csv('test_data.csv')
is_child_df = prepare_adult_child_dataset(test_df)
```

Этот скрипт может быть полезен для подготовки набора данных для задачи классификации одежды на взрослую и детскую на основе текстовых описаний.



## `prepare_male_female_dataset.py` скрипт выполняет следующие задачи:

1. Определяет класс `TextNormalizer` для нормализации и очистки текста (аналогично предыдущему скрипту).

2. Определяет функцию `prepare_male_female_dataset`, которая подготавливает набор данных для классификации одежды на мужскую и женскую. Она выполняет следующие шаги:
   - Фильтрует DataFrame `test_df` на основе категорий одежды.
   - Нормализует текстовые описания одежды с помощью класса `TextNormalizer`.
   - Определяет ключевые слова, связанные с мужской и женской одеждой.
   - Фильтрует одежду на основе наличия ключевых слов в описаниях.
   - Создает отдельные DataFrame для мужской и женской одежды.
   - Создает целевые метки (0 для женской одежды, 1 для мужской одежды).
   - Удаляет строки с пропущенными целевыми метками.
   - Создает DataFrame `male_female_df` с индексами и целевыми метками.

Входные данные:
- `test_df`: DataFrame с данными об одежде, включая столбцы 'category' и 'description'.

Выходные данные:
- `male_female_df`: DataFrame с двумя столбцами: 'index' (индексы элементов одежды) и 'target' (целевые метки: 0 для женской одежды, 1 для мужской одежды).

Скрипт использует библиотеки pandas, numpy, re, spacy, unicodedata и natasha.

Пример использования:
```python
test_df = pd.read_csv('test_data.csv')
male_female_df = prepare_male_female_dataset(test_df)
```

Этот скрипт может быть полезен для подготовки набора данных для задачи классификации одежды на мужскую и женскую на основе текстовых описаний. Он фильтрует одежду, используя ключевые слова, связанные с мужской и женской одеждой, и создает целевые метки для обучения модели классификации.

Обратите внимание, что скрипт предполагает наличие определенных категорий одежды и ключевых слов на русском языке. При необходимости эти параметры могут быть изменены в соответствии с конкретными требованиями проекта.




## `prepare_multiclass_dataset.py` скрипт выполняет следующие задачи:

1. Определяет функцию `replace_subcategory`, которая заменяет значения в столбце 'sub_category' на соответствующие значения из столбца 'category', если количество строк с определенным значением 'sub_category' меньше 11. Это делается для уменьшения количества классов в задаче многоклассовой классификации.

2. Определяет функцию `prepare_multiclass_dataset`, которая подготавливает набор данных для многоклассовой классификации. Она выполняет следующие шаги:
   - Вызывает функцию `replace_subcategory` для замены значений 'sub_category' на основе их встречаемости.
   - Создает экземпляр `LabelEncoder` из библиотеки scikit-learn для кодирования категориальных меток в числовые.
   - Преобразует значения столбца 'sub_category' в числовые метки с помощью `LabelEncoder`.
   - Создает DataFrame `multiclass_df` с индексами и целевыми метками.

3. Если скрипт запущен напрямую (а не импортирован как модуль), он выполняет следующие действия:
   - Определяет аргументы командной строки для входного файла DataFrame (--input_file) и выходного файла CSV (--output_file).
   - Загружает тестовый DataFrame из указанного входного файла.
   - Вызывает функцию `prepare_multiclass_dataset` для подготовки данных.
   - Сохраняет результирующий DataFrame в указанный выходной файл CSV.

Входные данные:
- `test_df`: DataFrame с данными, включая столбцы 'category' и 'sub_category'.

Выходные данные:
- `multiclass_df`: DataFrame с двумя столбцами: 'index' (индексы элементов) и 'target' (целевые метки для многоклассовой классификации).

Скрипт использует библиотеки pandas и scikit-learn.

Пример использования:
```bash
python script.py --input_file test_data.csv --output_file multiclass_labels.csv
```

Этот скрипт может быть полезен для подготовки набора данных для задачи многоклассовой классификации, где целевая переменная имеет множество категорий. Он уменьшает количество классов, заменяя редкие значения 'sub_category' на соответствующие значения 'category', и преобразует категориальные метки в числовые с помощью `LabelEncoder`. Результирующий DataFrame сохраняется в файл CSV для дальнейшего использования в задаче многоклассовой классификации.
