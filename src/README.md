 # Исходный код для пайплайна
### Суммарное описание скриптов
Скрипт `__init__.py`:**

Этот скрипт запускает комплексный пайплайн для обработки данных, обучения модели, генерации эмбеддингов и вычисления метрик. Вот основные задачи, которые выполняет скрипт:

- **Подготовка данных и изображений**: Загружает данные из файла Parquet и исходные изображения, обрабатывает изображения до заданного размера и сохраняет обработанные данные и изображения в указанные директории.
- **Обучение модели**: Использует подготовленные данные для обучения модели с заданными параметрами, такими как количество эпох, размер пакета и скорость обучения. Обученная модель сохраняется в указанной директории.
- **Генерация эмбеддингов**: С использованием обученной модели генерирует эмбеддинги для обработанных данных и сохраняет их в отдельный файл.
- **Вычисление метрик**: Запускает скрипт для вычисления метрик, используя сгенерированные эмбеддинги и подготовленные метки данных. Результаты метрик сохраняются в указанную директорию.

Скрипт также включает в себя создание необходимых директорий и подготовку меток данных для различных задач классификации. Он предназначен для интеграции с Wandb для отслеживания проекта и результатов.

```bash
python __init__.py --parquet_file "path/to/your/datafile.parquet" \
                       --raw_images_dir "path/to/raw/images" \
                       --processed_data_dir "path/to/save/processed/data" \
                       --processed_images_dir "path/to/save/processed/images" \
                       --model_save_dir "path/to/save/model" \
                       --embeddings_dir "path/to/save/embeddings" \
                       --results_dir "path/to/save/results" \
                       --project_name "your_project_name" \
                       --num_epochs 2 \
                       --batch_size 32 \
                       --lr 0.00006 \
                       --default_image_size 384 384 \
                       --emb_batch_size 32
```

**1. Скрипт `data_preparation.py`:**

Этот скрипт предназначен для предварительной обработки данных. Он выполняет следующие задачи:
- Загружает и обрабатывает изображения, изменяя их размер до заданного формата.
- Загружает и обрабатывает данные из файла формата Parquet.
- Удаляет строки с отсутствующими заголовками и описаниями.
- Преобразует идентификаторы изображений в пути к файлам изображений.
- Сохраняет обработанные данные в формате CSV.

**Пример использования:**
```bash
python data_preprocessing.py --file_path <path_to_parquet_file> --base_image_path <path_to_images> --processed_data_path <path_to_save_processed_data> --processed_images_path <path_to_save_resized_images> --default_image_size 384 384
```

**2. Скрипт `train_model.py`:**

Этот скрипт предназначен для обучения модели ruCLIP на предварительно обработанных данных. Он выполняет следующие задачи:
- Загружает модель ruCLIP и необходимые компоненты.
- Загружает обработанные данные из CSV-файла, созданного в `data_preprocessing.py`.
- Создает DataLoader для обучения модели.
- Настраивает оптимизатор и планировщик обучения.
- Обучает модель на основе данных, отслеживая прогресс с помощью tqdm и wandb.
- Сохраняет обученную модель после каждой эпохи.

**Пример использования:**
```bash
python train_model.py --file_path <path_to_parquet_file> --base_image_path <path_to_images> --processed_data_path <path_to_processed_csv> --model_save_path <path_to_save_model> --project_name fine-tuning-ruclip --num_epochs 2 --batch_size 32 --lr 1e-6
```

**3. Скрипт `generate_embeddings.py`:**

Этот скрипт предназначен для генерации эмбеддингов текста и изображений, используя предварительно обученную модель ruCLIP или её дообученную версию. Он выполняет следующие задачи:

- Загружает базовую модель ruCLIP или использует указанную дообученную модель.
- Инициализирует предсказатель ruCLIP для генерации эмбеддингов.
- Загружает данные из CSV-файла, который должен содержать колонки 'title' и 'image_path'.
- Последовательно обрабатывает данные, генерируя эмбеддинги для текстов и изображений.
- Сохраняет полученные эмбеддинги в файл формата NPZ.

### Классы и Методы

- **`EmbeddingPipeline`**:
  - **Инициализация**:
    - Загружает модель ruCLIP, настраивает устройство для вычислений (CPU или GPU).
    - Если указан путь к дообученной модели, загружает её веса.
  - **`TextDataset`**: Подкласс для создания датасета из текстов и путей к изображениям.
  - **`get_embeddings`**: Обрабатывает данные пакетами, извлекая эмбеддинги для текста и соответствующих изображений.

- **`generate_embeddings`**:
  - Генерирует эмбеддинги, используя экземпляр `EmbeddingPipeline`.
  - Сохраняет эмбеддинги в указанный файл.

### Пример использования:

```bash
python generate_embeddings.py \
    --fine_tuned_model_path <path_to_fine_tuned_model> \
    --processed_data_csv <path_to_processed_data_csv> \
    --output_path <path_to_save_embeddings> \
    --batch_size 32
```


**4. Скрипт `compute_metrics.py`:**

Этот скрипт предназначен для автоматизации процесса вычисления метрик для различных задач классификации, используя разные модели и подходы. Он выполняет следующие задачи:

- **Подготавливает данные** для различных задач классификации, таких как определение пола (Male/Female), взрослый/ребёнок (Adult/Child), товары взрослых по признаку (IsAdult), и мультиклассовая классификация по категориям и подкатегориям (Multiclass).
- **Вызывает скрипты подготовки меток** для каждой задачи, создавая соответствующие файлы с метками.
- **Вызывает скрипты вычисления метрик** для каждой задачи, используя модели как MLP, так и логистическую регрессию.
- **Сохраняет результаты** вычислений в различные файлы для анализа и сравнения.

### Описание функций

- **`run_preparation_script`**:
  - Запускает скрипты для подготовки меток (labels) для различных задач классификации.
  - Примеры включают подготовку данных для бинарной классификации (Male/Female, Adult/Child, IsAdult) и мультиклассовой классификации (Multiclass).

- **`run_compute_metrics_script`**:
  - Вызывает скрипты для вычисления метрик, используя предварительно подготовленные данные и эмбеддинги.
  - Осуществляет вычисление метрик для различных моделей (MLP, логистическая регрессия) и разных типов задач (бинарная, мультиклассовая).

### Процесс работы скрипта

1. **Подготовка меток для классификации**:
   - Для задач **Male/Female**, **Adult/Child**, **IsAdult**:
     - Использует соответствующие скрипты подготовки (`prepare_male_female_dataset.py`, `prepare_adult_child_dataset.py`, `prepare_is_adult_dataset.py`) для создания файлов с метками.
   - Для задачи **Multiclass**:
     - Использует скрипт `prepare_multiclass_dataset.py` для подготовки меток.

2. **Вычисление метрик**:
   - Для каждой задачи:
     - Вызывает скрипты (`compute_metrics_mlp_binary.py`, `compute_metrics_logreg_binary.py` для бинарных метрик и `compute_metrics_mlp_multiclass.py`, `compute_metrics_multiclass_logreg.py` для мультиклассовых метрик).
     - Сохраняет результаты в CSV-файлы для дальнейшего анализа.

### Пример использования:

```bash
python compute_all_metrics.py \
    --input_file <path_to_processed_csv> \
    --emb_paths <path_to_embeddings1.npz> <path_to_embeddings2.npz> \
    --model_names model1 model2
```

**Параметры командной строки:**

- `--input_file`: Путь к CSV-файлу с обработанными данными.
- `--emb_paths`: Пути к файлам с эмбеддингами, используемые для вычисления метрик.
- `--model_names`: Имена моделей, используемые для анализа и вычисления метрик.

### Описание работы скрипта:

1. **Инициализация и Подготовка данных**:
   - Скрипт начинает с подготовки меток для всех указанных задач классификации.
   - Для каждой задачи создаётся файл с метками, который затем используется для вычисления метрик.

2. **Вычисление метрик**:
   - Для каждой задачи запускаются скрипты вычисления метрик для MLP и логистической регрессии.
   - Результаты сохраняются в отдельные файлы, что позволяет легко сравнивать производительность различных моделей и подходов.


